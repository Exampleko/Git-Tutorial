# EdgePipe

# VI. EVALUATION

**EdgePipe**의 구현 및 실험 설정, 그리고 다른 분할 방식들과의 성능 비교에 대한 설명

♣ 기본 설정
    
1. **EdgePipe 구현 및 데이터셋**

- **프레임워크**: EdgePipe는 **TensorFlow 1.15.0**과 **Python 3.7**을 사용
- **사용된 데이터셋**: MNIST, Fashion-MNIST, EMNIST, CIFAR-10 데이터셋
    
    각각 60,000개의 학습 데이터와 10,000개의 테스트 데이터가 있으며, 주로 **Fashion-MNIST** 데이터를 통해 실험 결과를 사용하여 성능을 평가할것임
    
- **모델 구조**: 실험에 사용된 DNN 모델은 하나의 입력층과 5개의 밀집(Dense) 레이어로 구성되어 있으며, **128개의 뉴런을 가진 4개의 숨겨진 레이어**로 이루어짐. **ReLU 활성화 함수**와 **경사 하강법 옵티마이저**(learning rate: 0.01)를 사용하고, 배치 크기는 100, **소프트맥스 교차 엔트로피 손실 함수**를 사용
- **분산 학습 최적화**: 레이어 간 통신이 많은 최적화 알고리즘 대신, 기본 옵티마이저를 사용하여 통신 비용을 줄였음

<br>

2. **무선 엣지 디바이스 환경 설정**

- **네트워크 구성**: 50×50m² 크기의 공간에 6개의 엣지 디바이스를 무작위로 배치한 시뮬레이션 환경. 패킷 수신 비율(PRR)은 80.9%로 설정되었으며, **경로 손실 모델**(path-loss shadowing model)과 **가우시안 노이즈 모델**을 통해 구현됨
- **PRR 측정 방법**: 두 디바이스 간의 PRR은 50개의 패킷을 전송한 후 성공적으로 수신된 패킷 수를 세어 계산하였다.
- **네트워크 품질 평가**: PRR은 네트워크 품질의 대표적인 척도로 사용되며, **패킷 손실**과 관련된 네트워크 처리량을 고려하여 설정됨
- 순전파에서 디바이스간의 전송 실패 시에는 입력 신호를 0으로 처리하여 학습이 중단되지 않고 계속해서 이어질 수 있도록 함 → 100번의 실험을 통해 성능을 측정하여 아래와 같은 의미를 도출함
    
    1. **통신 실패 시 성능 영향 평가**
    
    - **Forward Pass(순전파)** 중 **통신 실패**가 발생했을 때, 입력 신호가 0으로 처리된 상황에서 **모델의 학습 성능**이 얼마나 유지되는지를 평가함
    - 이를 통해, 통신 실패가 발생하더라도 **EdgePipe가 안정적인 학습 성능**을 유지할 수 있는지 확인
    
    2. **평균 성능 및 표준 편차 측정**
    
    - 100번의 반복 테스트를 통해 **통신 실패와 같은 변동 요인**이 **모델 성능**에 미치는 영향을 확인
    - **평균 성능**은 EdgePipe가 일반적인 학습 과정에서 얼마나 일관되게 좋은 성능을 보여주는지를 나타내고, **표준 편차**는 통신 실패로 인해 성능 변동이 얼마나 심한지, 즉 시스템의 **안정성**을 나타냄
    
    따라서, **통신 실패 상황에서의 학습 성능**과 **분산 학습 환경에서의 성능 변동성**을 평가하기 위한 테스트라고 볼 수 있다

<br>    

3. **뉴런-디바이스 매핑 알고리즘 (유전 알고리즘 적용)**

- **유전 알고리즘**: **슈퍼 뉴런을 디바이스에 최적화하여 매핑**하기 위해 **유전 알고리즘**이 사용되었다. 유전 알고리즘은 여러 세대에 걸쳐 매핑을 최적화하며, 각 세대에서 최적의 매핑을 찾는 과정을 반복한다
- **1000번(세대) 반복**: 6개의 디바이스를 사용하는 경우, **1000 세대**의 반복을 통해 최적의 슈퍼 뉴런-디바이스 매핑을 찾는다. 이때 **Hadamard 곱**을 사용하여 매핑 상태의 안정성을 확인하고, 안정된 상태에 도달할 때까지 반복

<br>

4. **실험 설정의 성능 비교**

EdgePipe의 하이브리드 **분할 방식을** 다른 세 가지 분할 방식과 성능을 비교함

- **Vertical Allocation(수직 분할)**: PipeDream에서 파생된 방식으로, 순전파와 역전파가 1:1로 처리되며 가중치가 저장되는 방식.
- **Horizontal Allocation(수평 분할)**: 모델의 각 레이어가 여러 디바이스에 나누어 처리됨.
- **Naive 방식**: 단일 디바이스에서 모든 모델을 처리하는 방식.

---

EdgePipe의 **스케줄링 효율성**을 평가하기 위해 사용된 비교 ****실험

- **Model Parallelism:** **파이프라인 가속이 없는** 모델 병렬 처리 방식으로, EdgePipe의 파이프라인 처리 방식과 비교하는 역할을 한다
- **GPipe:** **마이크로 배치 기반 파이프라인 처리**를 사용하는 방식으로, **수직 분할**과 **마이크로 배치로 인한 통신 오버헤드**가 있는 방식

---

**neuron-to-device mapping** method 성능 비교 실험

- **Random 방식:** **슈퍼 뉴런을 무작위로 디바이스에 할당**하여 최적화되지 않은 상태에서의 성능을 비교

 EdgePipe의 **파이프라인 가속**과 **슈퍼 뉴런-디바이스 매핑 최적화**가 다른 방식들에 비해 얼마나 효율적인지를 확인하고자 함

1. **파이프라인 스케줄링에서 기본 타임슬롯을 정의하기 위한 시간 측정**
    - **필요성: 파이프라인 스케줄링**을 위해서는 **고정된 타임슬롯**이 필요함.
        - 각 디바이스가 순차적으로 작업을 처리하기 때문에, 모든 디바이스가 일정한 시간 간격으로 데이터를 처리해야 한다. 타임슬롯은 각 디바이스가 **계산을 수행하고 통신하는 데 필요한 시간**을 고려하여 설정
    - **타임슬롯을 결정하는 방식**은 **최악의 경우**(worst case) 시간을 기반으로 한다. 이는 모든 가능한 상황에서 **가장 오래 걸리는 계산 시간**과 **통신 시간**을 합산하여 설정됨. 이러한 방식으로 타임슬롯을 정하는 이유는, 모든 디바이스가 동시에 일을 처리할 수 있도록 보장하기 위함임
        - 계산 시간: **순전파(Forward pass)와 역전파(Backward pass)** 동안 **각 레이어와 인접한 레이어 간의 계산 시간**
        - 통신 시간: 파이프라인의 다른 디바이스로 데이터(최대 패킷 크기)를 전달하는 데 걸리는 시간
    - **전체 훈련 시간**은 각 분할 방식에서 필요한 타임슬롯 수를 기반으로 계산한다.
    - 요약: 
    이 부분에서 말하고자 하는 것은 **EdgePipe의 파이프라인 스케줄링**을 위해 **계산 시간과 통신 시간**을 측정하고, 이를 기반으로 **고정된 타임슬롯**을 설정하는 방법. 특히, **최악의 경우 시간**을 기준으로 타임슬롯을 정하여, 모든 디바이스가 작업을 원활하게 진행할 수 있도록 보장함

