# EdgePipe

# VI. EVALUATION

**EdgePipe**의 구현 및 실험 설정, 그리고 다른 분할 방식들과의 성능 비교에 대한 설명

♣ 기본 설정
    
1. **EdgePipe 구현 및 데이터셋**

- **프레임워크**: EdgePipe는 **TensorFlow 1.15.0**과 **Python 3.7**을 사용
- **사용된 데이터셋**: MNIST, Fashion-MNIST, EMNIST, CIFAR-10 데이터셋
    
    각각 60,000개의 학습 데이터와 10,000개의 테스트 데이터가 있으며, 주로 **Fashion-MNIST** 데이터를 통해 실험 결과를 사용하여 성능을 평가할것임
    
- **모델 구조**: 실험에 사용된 DNN 모델은 하나의 입력층과 5개의 밀집(Dense) 레이어로 구성되어 있으며, **128개의 뉴런을 가진 4개의 숨겨진 레이어**로 이루어짐. **ReLU 활성화 함수**와 **경사 하강법 옵티마이저**(learning rate: 0.01)를 사용하고, 배치 크기는 100, **소프트맥스 교차 엔트로피 손실 함수**를 사용
- **분산 학습 최적화**: 레이어 간 통신이 많은 최적화 알고리즘 대신, 기본 옵티마이저를 사용하여 통신 비용을 줄였음

<br>

2. **무선 엣지 디바이스 환경 설정**

- **네트워크 구성**: 50×50m² 크기의 공간에 6개의 엣지 디바이스를 무작위로 배치한 시뮬레이션 환경. 패킷 수신 비율(PRR)은 80.9%로 설정되었으며, **경로 손실 모델**(path-loss shadowing model)과 **가우시안 노이즈 모델**을 통해 구현됨
- **PRR 측정 방법**: 두 디바이스 간의 PRR은 50개의 패킷을 전송한 후 성공적으로 수신된 패킷 수를 세어 계산하였다.
- **네트워크 품질 평가**: PRR은 네트워크 품질의 대표적인 척도로 사용되며, **패킷 손실**과 관련된 네트워크 처리량을 고려하여 설정됨
- 순전파에서 디바이스간의 전송 실패 시에는 입력 신호를 0으로 처리하여 학습이 중단되지 않고 계속해서 이어질 수 있도록 함 → 100번의 실험을 통해 성능을 측정하여 아래와 같은 의미를 도출함
    
    1. **통신 실패 시 성능 영향 평가**
    
    - **Forward Pass(순전파)** 중 **통신 실패**가 발생했을 때, 입력 신호가 0으로 처리된 상황에서 **모델의 학습 성능**이 얼마나 유지되는지를 평가함
    - 이를 통해, 통신 실패가 발생하더라도 **EdgePipe가 안정적인 학습 성능**을 유지할 수 있는지 확인
    
    2. **평균 성능 및 표준 편차 측정**
    
    - 100번의 반복 테스트를 통해 **통신 실패와 같은 변동 요인**이 **모델 성능**에 미치는 영향을 확인
    - **평균 성능**은 EdgePipe가 일반적인 학습 과정에서 얼마나 일관되게 좋은 성능을 보여주는지를 나타내고, **표준 편차**는 통신 실패로 인해 성능 변동이 얼마나 심한지, 즉 시스템의 **안정성**을 나타냄
    
    따라서, **통신 실패 상황에서의 학습 성능**과 **분산 학습 환경에서의 성능 변동성**을 평가하기 위한 테스트라고 볼 수 있다

<br>    

3. **뉴런-디바이스 매핑 알고리즘 (유전 알고리즘 적용)**

- **유전 알고리즘**: **슈퍼 뉴런을 디바이스에 최적화하여 매핑**하기 위해 **유전 알고리즘**이 사용되었다. 유전 알고리즘은 여러 세대에 걸쳐 매핑을 최적화하며, 각 세대에서 최적의 매핑을 찾는 과정을 반복한다
- **1000번(세대) 반복**: 6개의 디바이스를 사용하는 경우, **1000 세대**의 반복을 통해 최적의 슈퍼 뉴런-디바이스 매핑을 찾는다. 이때 **Hadamard 곱**을 사용하여 매핑 상태의 안정성을 확인하고, 안정된 상태에 도달할 때까지 반복

<br>

4. **실험 설정의 성능 비교**

- EdgePipe의 하이브리드 **분할 방식을** 다른 세 가지 분할 방식과 성능을 비교함

    - **Vertical Allocation(수직 분할)**: PipeDream에서 파생된 방식으로, 순전파와 역전파가 1:1로 처리되며 가중치가 저장되는 방식.
    - **Horizontal Allocation(수평 분할)**: 모델의 각 레이어가 여러 디바이스에 나누어 처리됨.
    - **Naive 방식**: 단일 디바이스에서 모든 모델을 처리하는 방식.

<br>   
<br>   

- EdgePipe의 **스케줄링 효율성**을 평가하기 위해 사용된 비교 실험

    - **Model Parallelism:** **파이프라인 가속이 없는** 모델 병렬 처리 방식으로, EdgePipe의 파이프라인 처리 방식과 비교하는 역할을 한다
    - **GPipe:** **마이크로 배치 기반 파이프라인 처리**를 사용하는 방식으로, **수직 분할**과 **마이크로 배치로 인한 통신 오버헤드**가 있는 방식

<br> 
<br>   

- **neuron-to-device mapping** method 성능 비교 실험

    - **Random 방식:** **슈퍼 뉴런을 무작위로 디바이스에 할당**하여 최적화되지 않은 상태에서의 성능을 비교

<br>
<br>

- EdgePipe의 **파이프라인 가속**과 **슈퍼 뉴런-디바이스 매핑 최적화**가 다른 방식들에 비해 얼마나 효율적인지를 확인하고자 함

    - **파이프라인 스케줄링에서 기본 타임슬롯을 정의하기 위한 시간 측정**
        - **필요성: 파이프라인 스케줄링**을 위해서는 **고정된 타임슬롯**이 필요함.
            - 각 디바이스가 순차적으로 작업을 처리하기 때문에, 모든 디바이스가 일정한 시간 간격으로 데이터를 처리해야 한다. 타임슬롯은 각 디바이스가 **계산을 수행하고 통신하는 데 필요한 시간**을 고려하여 설정
        - **타임슬롯을 결정하는 방식**은 **최악의 경우**(worst case) 시간을 기반으로 한다. 이는 모든 가능한 상황에서 **가장 오래 걸리는 계산 시간**과 **통신 시간**을 합산하여 설정됨. 이러한 방식으로 타임슬롯을 정하는 이유는, 모든 디바이스가 동시에 일을 처리할 수 있도록 보장하기 위함임
            - 계산 시간: **순전파(Forward pass)와 역전파(Backward pass)** 동안 **각 레이어와 인접한 레이어 간의 계산 시간**
            - 통신 시간: 파이프라인의 다른 디바이스로 데이터(최대 패킷 크기)를 전달하는 데 걸리는 시간
        - **전체 훈련 시간**은 각 분할 방식에서 필요한 타임슬롯 수를 기반으로 계산한다.
        - 요약: 
        이 부분에서 말하고자 하는 것은 **EdgePipe의 파이프라인 스케줄링**을 위해 **계산 시간과 통신 시간**을 측정하고, 이를 기반으로 **고정된 타임슬롯**을 설정하는 방법. 특히, **최악의 경우 시간**을 기준으로 타임슬롯을 정하여, 모든 디바이스가 작업을 원활하게 진행할 수 있도록 보장함

------------

♣ A. Distributed Learning

EdgePipe의 **분산 학습 성능**을 다양한 환경에서 평가해봄

→ 보델 분할 방법, 뉴런-디바이스 매핑 방법, 파이스라인 스케줄링 방법의 비교를 통해 네트워크 링크 상태에 따른 성능을 평가한다.

<br>

1.  **모델 분할 및 학습 성능 비교 (Fig5)**

EdgePipe의 하이브리드 분할 방식과 다른 분할 방식을 비교하여, **링크 실패(통신 실패) 유무에 따라 학습 성능을 비교**함 

- 링크 실패가 없는 환경에서의 EdgePipe는 파이프라인 가속 효과 덕분에 Navie방식보다 더 빠르게 수렴하며, 다른 방식들도 거의 동일한 학습 성능을 보인다.
- 링크 실패가 있는 실제 무선 네트워크 상황에서는 무선 링크의 변동성으로 인해 성능 저하가 발생함. 하지만 하이브리드 분할 방식은 다른 방식보다 더 안정적으로 동작함.
    - Vertical: 레이어 전체를 하나의 디바이스가 처리하므로, 중간 결과 손실이 발생할 경우 불안정한 성능을 보임
    - Horizontal: 통신 실패가 발생하면 역전파 실패로 인해 학습 경로가 차단되고 모델이 수렴하지 못 함. 실험에서는 수평 분할 방식이 학습이 거의 이루어지지 않아 매우 낮은 Accuracy를 기록함
    - Hybrid: 불안정한 무선 통신 환경에도 불구하고 상대적으로 안정적인 성능을 유지하면서 수직 및 수평 분할 방식보다 높은 Accuracy를 보임

![스크린샷 2024-09-24 012233.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b3ef78f-41d0-464c-839f-5c6f8634cf72/01f750a6-0f24-4c05-b7cf-638cddc97bb7/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7_2024-09-24_012233.png)

<br>

2.  **레이어 간 학습 경로 유지 평가 (Fig6)**

링크 실패가 발생할 때, 각 분할 방식이 **레이어 간 학습 경로를 어떻게 유지하는지** 분석함

- Vertical: 디바이스간 통신이 적어 평균적으로 레이어 간의 학습 업데이트가 원활하게 이루어진다. !하지만! 특정 레이어를 담당하는 디바이스가 비활성화되면 전체 학습이 중단되는 불안정성을 보임
- Horizontal: 디바이스 간 통신 빈도가 높아 통신 비용이 과도하게 발생하며, 디바이스의 전송 손실이 생기면 전체 학습이 중단된다. 또한 파이프라인 가속 효과를 거의 활용하지 못 함을 보임
- Hybrid: 일부 레이어 간 전파 성능이 저하되긴 했지만, 인접한 레이어 간의 슈퍼 뉴런 구조 덕분에 비교적 안정적인 학습을 진행함

<br>

3. **파이프라인 스케줄링과 학습 시간 분석 (Fig6)**

실험에서는 **슈퍼 뉴런의 레이어 수(Mlayers)를 조정**하여 파이프라인 스케줄링이 학습 시간에 미치는 영향을 분석함.

- Vertical: 최대 6개의 pipeline stages를 통해 파이프라인 가속 효과를 최대한으로 활용하여 학습 시간을 단축하였음
    - 단, 중간 학습 경로에서 오류가 발생하면 전체 계산이 중단되는 문제가 있어 성능 분포가 이분화된 결과를 보인다.
- Horizontal: 파이프라인을 거의 활용하지 못해(디바이스간의 의존도가 높고 통신 오버헤드가 크기 때문에) 가장 많은 타임 슬롯을 소모했지만, 타임 슬롯의 길이가 짧아 학습 시간 자체는 합리적임
- Hybrid: 파이프라인 가속을 적절히 활용하여 균형 잡힌 성능을 보임
    - 슈퍼 뉴런의 레이어 수에 따른 테스트 정확도를 비교하였을 때 Mlayers=2일 때 가장 안정적이고 우수한 성능을 보임

결론: 디바이스의 성능을 좋게 하는 슈퍼 뉴런의 레이어 수를 적절히 선택해야 한다.

<br>

4. **파이프라인 가속 성능 비교 (Fig7)**
**EdgePipe의 파이프라인 병렬 처리**는 **모델 병렬 처리(without pipeline)** 및 **GPipe**와 비교하여 **학습 시간 단축**과 **테스트 정확도 향상을 입증함**

- EdgePipe는 파이프라인 가속을 통해 모델 병렬 처리 기법보다 학습 속도를 2.47배 가속하였음
- GPipe는 Vertical 분할 기반으로 동작하여 비슷한 성능을 보였으나, 마이크로 배치 병렬 처리로 인해 불안정한 학습 성능을 보임
- Horizontal 분할은 역전파 실패로 인해 모델이 수렴하지 못하여 성능이 크게 뒤처짐

결론: EdgePipe with Hybrid allocation shows relatively more stable learning

<br>

5. **뉴런-디바이스 매핑 평가**

뉴런을 디바이스에 매핑하는 방식이 학습 성능에 미치는 영향을 평가함

- EdgePipe의 유전 알고리즘 → 랜덤 매핑과 비교하여 더 나은 학습 성능을 보여주었으며, 브루트 포스 방식(Upper)과 유사한 성능을 기록함

<br>

6. **결론**

- **EdgePipe의 Hybrid Allocation, super neuron structure**와 **super neuron-to-device mapping**은 EdgePipe의 핵심 구성 요소로, **파이프라인 가속**과 결합되어 **빠른 학습 시간과 높은 안정성**을 달성하는 데 필수적이다.
⇒ 변동성 있는 무선 네트워크 환경에서도 높은 성능을 유지하는 데 중요한 역할을 한다!


-----------------

♣ B. Resilience Under Various Learning Environments

EdgePipe가 **다양한 학습 환경에서 얼마나 잘 적응하고 성능을 유지하는지**를 평가한다.
**무선 네트워크 환경의 변동성**과 **디바이스 구성** 등 여러 요인이 학습에 미치는 영향을 분석하고, 이러한 환경에서 EdgePipe의 하이브리드 분할 방식이 다른 방식들에 비해 얼마나 더 안정적으로 학습 성능을 유지하는지에 대해 검증한다.

1. **네트워크 변동성에 대한 회복력 (Link Volatility) (Fig.9 a,b)**
네트워크의 PRR(패킷 수신 비율)을 조절하여 **통신 링크의 변동성**을 다르게 설정하여 실험한다.

- Vertical: 네트워크 품질에 민감하게 반응하여 성능이 급격히 저하됨
- Hybrid: 네트워크 상황이 나빠져도 성능이 크게 저하되지 않아 상대적으로 안정적인 성능을 유지

<br>

2. **디바이스 분포에 따른 성능 (Device Distribution) (Fig.9 c)**

디바이스가 분포된 위치가 네트워크 연결성에 미치는 영향을 평가한 실험. 

동일한 자원을 사용해도 디바이스의 위치에 따라 네트워크 연결성에 큰 차이가 발생할 수 있음.

- Vertical: 디바이스 분포에 따라 성능 변화가 크게 나타남
- Hybrid: 디바이스 분포에 따른 성능 변화가 상대적으로 더 작았으며 더 안정적인 성능을 보임

<br>

3. **관심 영역(Region of Interest, RoI) 크기와 디바이스 수 변화 (Fig.9 d,e)**

네트워크에서 다루는 영역(Rol)이 커지거나 디바이스의 수가 줄어들면, 디바이스간의 거리나 연결성이 떨이지기때문에 통신 실패가 더 빈번하게 발생할 수 있음.

- Vertical: Rol이 커지면 중간 단계에서의 실패로 인해 성능이 크게 저하됨
- Hybrid: Rol이 커져 통신 실패가 늘어도 비교적 안정적인 학습 성능을 유지함.
    - **디바이스 수가 부족**하거나 **레이어 수가 너무 많아** 한 디바이스가 **여러 레이어를 동시에 처리해야 할 때**는, 하이브리드 방식이 **수평 분할 방식으로 전환**되면서 **디바이스 간의 병렬 처리 효율이 감소**할 수 있음
- 디바이스의 수가 충분할 경우 Vertical과 Hybrid는 유사한 성능을 보이지만, 디바이스의 수가 적을 경우 Hybrid가 더 나은 성능을 보임

<br>

4. **패킷 전송 실패에 대한 복구 방식 (Fig.9 f)**
**패킷 전송 실패를 복구**하기 위한 두 가지 방식으로 실험을 진행함

1. **r-TX**: 간단한 **중복 전송** 방식으로, 동일한 패킷을 두 번 전송하는 방식.
2. **ACK**: **재전송**을 통해 패킷 전송이 성공할 때까지 전송을 반복하는 방식.

두 방식 모두 패킷 전송 실패를 줄여 학습 성능을 향상시킴

!! Hybrid 분할 방식은 이러한 추가적인 전송 복구 없이도 네트워크 변동성에 상대적으로 안정적인 성능을 보임 ⇒ 슈퍼 뉴런 구조가 네트워크 불안정성에 대한 회복력을 제공하는 핵심 요소임을 시사함

<br>

5. 결론
**EdgePipe의 하이브리드 분할 방식**은 네트워크 변동성이나 통신 실패 같은 **불안정한 환경에서도 안정적인 학습 성능**을 유지할 수 있다!


---------------------

♣ C. Feasibility and Scalability of EdgePipe

**EdgePipe의 실현 가능성과** **확장성**을 다양한 학습 환경과 네트워크 모델을 사용해 검증한다.

1. **다양한 DNN 모델에서의 성능 검증** 
**DNN 구조의 레이어 수와 디바이스의 개수를 변경**하면서 EdgePipe의 성능을 검증한다.

- 하이브리드 분할 방식은 레이어의 수가 증가할 수록 Horizontal에 가까워지기 때문에 pipeline acceleration의 효과가 줄어 학습 속도가 느려짐. 하지만 여러 디바이스가 같은 레이어를 분할하여 처리하므로(너무 많이 나누지는 않고) 레이어 간 통신 오류로 인한 학습 실패를 방지할 수 있기 때문에 더 높은 테스트 정확도를 얻을 수 있음
    
    ⇒ 최종적으로는 다른 방법들보다 더 높은 테스트 정확도를 달성하게 됨

<br>

2. **CNN 모델에서의 성능 검증**

3개의 convolution layers와 4개의 fully connected layers로 구성된 CNN을 사용하여 EdgePipe의 성능을 검증함

⇒ CNN 모델이 DNN보다 더 나은 성능을 달성함 (CNN의 고유한 장점인 **합성곱층의 강력한 성능** 덕분)

⇒ 필요에 따라 CNN layer나 pooling layer와 같이 다른 유형의 레이어를 추가할 수 있음

(convolution layer와  pooling layer는 상대적으로 dense layer에 비해 계산 효율이 높고 자원 소모가 적다.)

⇒ 결론: 필요하다면 계산이 더 효율적인 convolution layer나 pooling layer를 추가로 쌓아 올려 모델의 성능을 높일 수 있음을 암시함

<br>

3. **실제 무선 환경에서의 성능 검증**
실험 결과, **EdgePipe의 하이브리드 분할**은 **실제 무선 네트워크 환경에서도 학습 및 추론 성능을 안정적으로 유지함을 보임**

<br>

4. 결론

**DNN과 CNN 구조 모두에서 하이브리드 분할 방식이 안정적인 성능**을 유지했으며, 특히 CNN에서는 DNN보다 더 빠르게 높은 성능에 도달함

**파이프라인 가속** 덕분에 학습 시간은 짧아지고, 성능은 더욱 향상됨
**실제 무선 네트워크 환경**에서도 EdgePipe는 안정적인 성능을 보였으며, **하이브리드 분할 방식**이 다양한 환경에서의 신뢰성을 입증함
⇒ **EdgePipe**가 다양한 학습 환경에서 **높은 확장성**과 **안정성**을 제공한다는 것을 검증함






